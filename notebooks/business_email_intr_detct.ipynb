{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ef8c9f1-70f4-4e70-82c1-28b999faa6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import re\n",
    "import mailbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8468126e-c5ec-49d5-b3f6-8b5675b7b53b",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d0e777c8-cfa1-4f54-aeca-a38fdc906069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_emails(mbox_messages):\n",
    "    email_bodies = []\n",
    "    email_subjects = []\n",
    "    email_ids = []\n",
    "    email_content_types = []\n",
    "    for i, message in enumerate(train_messages):\n",
    "        body = message.get_payload()\n",
    "        email_bodies.append(body)\n",
    "        if message['Subject']:\n",
    "            email_subjects.append(message['Subject'])\n",
    "        else:\n",
    "            email_subjects.append(\"Empty\")\n",
    "        email_ids.append(message['X-UID'])\n",
    "        if message['Content-Type']:\n",
    "            email_content_types.append(message['Content-Type'])\n",
    "        else:\n",
    "            email_content_types.append(\"Empty\")\n",
    "    return email_bodies, email_subjects, email_ids, email_content_types\n",
    "\n",
    "\n",
    "def del_punct_symbols(texts):\n",
    "    texts = [text.lower().replace('\\n',' ').replace('\\t',' ') for text in texts]\n",
    "    texts = [re.sub(r'[^\\w\\s]','',text) for text in texts]\n",
    "    return texts\n",
    "\n",
    "def del_stop_words(texts, stop_words):\n",
    "    return [[word for word in email.split() if word not in stop_words] for email in texts]\n",
    "\n",
    "def lemmatize_text(texts, lemmatizer):\n",
    "    return [[lemmatizer.lemmatize(word) for word in email] for email in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "79e379e9-14f1-4f15-86f2-45296eb85082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dmitriy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/dmitriy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3322bd94-7daf-4b81-bb2b-4e8f64c92e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages = mailbox.mbox('train.mbox')\n",
    "train_bodies, train_subjects, train_ids, train_content_types = parse_emails(test_messages)\n",
    "train = lemmatize_text(del_stop_words(del_punct_symbols(train_bodies), stop_words), lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0e981-b04e-48f2-99e5-4ea3e926fdf9",
   "metadata": {},
   "source": [
    "### DOC2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5d641176-d202-4f23-8980-7144454084b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tagged_document(list_of_list_of_words):\n",
    "    for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "        yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i])\n",
    "\n",
    "train_data_bds, test_data_bds = test_bodies[:3000], test_bodies[3000:] \n",
    "train_data_bds_tagged = list(create_tagged_document(train_data_bds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ffd08d6-c9d4-4b89-9ea4-164c47184683",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "model.build_vocab(train_data_bds_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "406a4ca0-8537-49d3-8178-3bc36f6ebdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_data_bds_tagged, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "82e0955d-efaf-4323-b859-9b4128e7276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2932, 1: 29, 2: 6, 3: 5, 16: 2, 449: 1, 877: 1, 2034: 1, 74: 1, 565: 1, 2851: 1, 2321: 1, 2013: 1, 611: 1, 2996: 1, 93: 1, 77: 1, 64: 1, 5: 1, 8: 1, 2733: 1, 49: 1, 1051: 1, 419: 1, 6: 1, 10: 1, 45: 1, 1708: 1, 89: 1, 1802: 1, 164: 1})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_data_bds_tagged)):\n",
    "    inferred_vector = model.infer_vector(train_data_bds_tagged[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])\n",
    "\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "feee4876-d039-41f9-a42c-35caf562cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([model.infer_vector(vec) for vec in test_data_bds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc8003e-3088-41b7-b4f5-359a9797fc6d",
   "metadata": {},
   "source": [
    "### OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d98e796c-8793-4795-8b9e-14c1b177f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "clf = OneClassSVM(gamma='auto').fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb71e2-a26a-49ac-bb7c-e195355dce88",
   "metadata": {},
   "source": [
    "### Test data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "491bf5e4-82b6-4019-8817-eda8e4e265aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages = mailbox.mbox('test.mbox')\n",
    "test_bodies, test_subjects, test_ids, test_content_types = parse_emails(test_messages)\n",
    "test_bodies = lemmatize_text(del_stop_words(del_punct_symbols(test_bodies), stop_words), lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5bbfa571-7d50-4b9a-a275-17605ce0d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([model.infer_vector(vec) for vec in test_bodies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4f74aab7-d152-44a2-b4a2-188b3aabe6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = clf.predict(X_test)\n",
    "res[res==-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "06857e35-ff87-4be4-b817-d3bb6949e8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 2279]\n",
      " [   1 2112]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(res, return_counts=True)\n",
    "\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f85e1e0-e790-4c29-b70e-372fbf1608b3",
   "metadata": {},
   "source": [
    "### Making submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7775b678-73a5-40db-9d90-4b10bc0c2f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = zip(test_ids, res)\n",
    "submission_df = pd.DataFrame(submission_data, columns = ['UID', 'VERDICT'])\n",
    "submission_df.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613b7c0-e94e-4d88-93d7-a3a0a9cd4842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
